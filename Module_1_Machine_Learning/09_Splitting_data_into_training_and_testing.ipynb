{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data into Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "- Understand why and how to split datasets into training and testing sets, and training, validation and testing sets.\n",
    "- Understand some technical nuances on splitting datasets such as reproducibility and how to deal with imbalanced datasets.\n",
    "- Implement dataset splits in Python with `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data into Training and Testing datasets\n",
    "\n",
    "When training a model we want to separate concerns in our datasets. We need a portion for our dataset to be the data the model trains on, this set is usually known as **training set**. We also need another portion of our data to evaluate the performance of our model (here we understand _performance_ as _some measure of how good the predictions of our model are_). This second dataset is known as **testing dataset**. We don't want these sets to be overlapping as this is a source of overfitting. In practice the proportions of these splits are around **70-30** to **90-10** percent (**train-test**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.5.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in c:\\python312\\lib\\site-packages (2.0.0)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.13.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\eder.trujillo\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\eder.trujillo\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached scikit_learn-1.5.0-cp312-cp312-win_amd64.whl (10.9 MB)\n",
      "Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.13.1-cp312-cp312-win_amd64.whl (45.9 MB)\n",
      "Installing collected packages: scipy, joblib, scikit-learn, pandas\n",
      "Successfully installed joblib-1.4.2 pandas-2.2.2 scikit-learn-1.5.0 scipy-1.13.1\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "%pip install scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making random splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "wine_ds = load_wine()\n",
    "wine_X = wine_ds.data\n",
    "wine_y = wine_ds.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_X,\n",
    "                                                    wine_y,\n",
    "                                                    train_size=TRAIN_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a seed for reproducibility\n",
    "\n",
    "When doing splits, we might want to ensure subsequent runs of the same training pipelines yield the same result. For doing that we want to make our split consistent across runs. Scikit-learn `train_test_split` function has an optional parameter for a \"random state\" which ensures the data split to be the same across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "TRAIN_SIZE = 0.8\n",
    "RANDOM_SEED = 314159\n",
    "\n",
    "wine_ds = load_wine()\n",
    "wine_X = wine_ds.data\n",
    "wine_y = wine_ds.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_X,\n",
    "                                                    wine_y,\n",
    "                                                    train_size=TRAIN_SIZE,\n",
    "                                                    random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into training, testing, and validation\n",
    "\n",
    "We can include additional validation of our model during the training phase. This can help us reduce overfitting. For this purpose we include a third split, which is usually known as a **validation set**. This set usually consists of **40** to **60** percent of the data that would be reserved for the testing set. The three of these sets should not be overlapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "TRAIN_SIZE = 0.8\n",
    "TEST_VAL_RATIO = 0.5\n",
    "RANDOM_SEED = 314159\n",
    "\n",
    "wine_ds = load_wine()\n",
    "wine_X = wine_ds.data\n",
    "wine_y = wine_ds.target\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(wine_X,\n",
    "                                                    wine_y,\n",
    "                                                    train_size=TRAIN_SIZE,\n",
    "                                                    random_state=RANDOM_SEED)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp,\n",
    "                                                y_temp,\n",
    "                                                train_size=TEST_VAL_RATIO,\n",
    "                                                random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling imbalanced data or time-series\n",
    "\n",
    "When handling highly imbalanced(skewed) data, it is possible that some data class gets misrepresented in either the training or testing/validation sets. For instance, if we have a dataset for fraud occurrences, we might have a low percent of fraud events, which might not make it to the testing dataset. Other kind of consideration when splitting data might be when working with time-based events, for instance when dealing with forecasting, we would like to have data around the same time points in all of our dataset splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Split\n",
    "\n",
    "A stratified split ensures class distribution in classification models remains consistent across dataset splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "TRAIN_SIZE = 0.8\n",
    "TEST_VAL_RATIO = 0.5\n",
    "RANDOM_SEED = 314159\n",
    "\n",
    "wine_ds = load_wine()\n",
    "wine_X = wine_ds.data\n",
    "wine_y = wine_ds.target\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(wine_X,\n",
    "                                                    wine_y,\n",
    "                                                    train_size=TRAIN_SIZE,\n",
    "                                                    random_state=RANDOM_SEED,\n",
    "                                                    stratify=wine_y)\n",
    "# We want to use target columns as these mark our classes in a classification model\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp,\n",
    "                                                y_temp,\n",
    "                                                train_size=TEST_VAL_RATIO,\n",
    "                                                random_state=RANDOM_SEED,\n",
    "                                                stratify=y_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-series splits\n",
    "\n",
    "When working with time series, a method to split data consists in:\n",
    "- Splitting first the data into segments corresponding a time period.\n",
    "- Create splits for all of these segments.\n",
    "- Join resulting datasets.\n",
    "The `scikit-learn` library also contains a helper module for this kind of split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "bike_sharing = fetch_openml(\"Bike_Sharing_Demand\", version=2, as_frame=True)\n",
    "bike_df = bike_sharing.frame\n",
    "# We retrieve a bike sharing dataset from OpenML repository.\n",
    "bike_y = bike_df[\"count\"]\n",
    "# We use the quantity of rentals as labels.\n",
    "bike_X = bike_df.drop(\"count\", axis=\"columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      season  year  month  hour holiday  weekday workingday weather   temp  \\\n",
      "0     spring     0      1     0   False        6      False   clear   9.84   \n",
      "1     spring     0      1     1   False        6      False   clear   9.02   \n",
      "2     spring     0      1     2   False        6      False   clear   9.02   \n",
      "3     spring     0      1     3   False        6      False   clear   9.84   \n",
      "4     spring     0      1     4   False        6      False   clear   9.84   \n",
      "...      ...   ...    ...   ...     ...      ...        ...     ...    ...   \n",
      "2894  summer     0      5    12   False        4       True   clear  21.32   \n",
      "2895  summer     0      5    13   False        4       True   clear  22.14   \n",
      "2896  summer     0      5    14   False        4       True   clear  22.14   \n",
      "2897  summer     0      5    15   False        4       True   clear  22.96   \n",
      "2898  summer     0      5    16   False        4       True   clear  23.78   \n",
      "\n",
      "      feel_temp  humidity  windspeed  \n",
      "0        14.395      0.81     0.0000  \n",
      "1        13.635      0.80     0.0000  \n",
      "2        13.635      0.80     0.0000  \n",
      "3        14.395      0.75     0.0000  \n",
      "4        14.395      0.75     0.0000  \n",
      "...         ...       ...        ...  \n",
      "2894     25.000      0.34    23.9994  \n",
      "2895     25.760      0.30    39.0007  \n",
      "2896     25.760      0.28    30.0026  \n",
      "2897     26.515      0.26    32.9975  \n",
      "2898     27.275      0.24    27.9993  \n",
      "\n",
      "[2899 rows x 12 columns]       season  year  month  hour holiday  weekday workingday weather   temp  \\\n",
      "2899  summer     0      5    17   False        4       True   clear  22.96   \n",
      "2900  summer     0      5    18   False        4       True   clear  22.96   \n",
      "2901  summer     0      5    19   False        4       True   clear  22.14   \n",
      "2902  summer     0      5    20   False        4       True   clear  20.50   \n",
      "2903  summer     0      5    21   False        4       True   clear  20.50   \n",
      "...      ...   ...    ...   ...     ...      ...        ...     ...    ...   \n",
      "5790    fall     0      9    17   False        6      False   clear  29.52   \n",
      "5791    fall     0      9    18   False        6      False   clear  29.52   \n",
      "5792    fall     0      9    19   False        6      False   clear  28.70   \n",
      "5793    fall     0      9    20   False        6      False   clear  28.70   \n",
      "5794    fall     0      9    21   False        6      False   clear  27.88   \n",
      "\n",
      "      feel_temp  humidity  windspeed  \n",
      "2899     26.515      0.26    26.0027  \n",
      "2900     26.515      0.26    19.0012  \n",
      "2901     25.760      0.28    15.0013  \n",
      "2902     24.240      0.34    11.0014  \n",
      "2903     24.240      0.36    12.9980  \n",
      "...         ...       ...        ...  \n",
      "5790     34.090      0.70    15.0013  \n",
      "5791     34.090      0.70    11.0014  \n",
      "5792     33.335      0.74     8.9981  \n",
      "5793     33.335      0.79    11.0014  \n",
      "5794     31.820      0.83     8.9981  \n",
      "\n",
      "[2896 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "ts_cv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "all_splits = list(ts_cv.split(bike_X, bike_y)) # Gets all splits indices\n",
    "\n",
    "# We can recover them as follows:\n",
    "train_0, test_0 = all_splits[0]\n",
    "\n",
    "print(\n",
    "    bike_X.iloc[train_0],\n",
    "    bike_X.iloc[test_0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources:\n",
    "- https://medium.com/data-and-beyond/how-to-split-data-in-machine-learning-5-simple-strategies-and-python-examples-a500c3f2f750#:~:text=Data%20Splitting%20is%20an%20important,and%20finally%20evaluating%20its%20performance. \n",
    "- https://scikit-learn.org/stable/auto_examples/applications/plot_cyclical_feature_engineering.html "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
