{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Máquinas de vectores de soporte (SVM)**\n",
    "\n",
    "Se utilizan principalmente en problemas de clasificación. El objetivo principal de una `SVM` es encontrar el hiperplano en un espacio de múltiples dimensiones que mejor separa las distintas clases de datos. <br /><br />\n",
    "Un hiperplano es una subvariedad de un espacio de mayor dimensión (en un espacio tridimensional, sería un plano; en un espacio bidimensional, sería una línea).\n",
    "\n",
    "`EJEMPLOS DE USO:`<br />\n",
    "Clasificación de Imágenes: Una SVM puede ser entrenada para distinguir entre diferentes tipos de objetos en imágenes.<br>\n",
    "\n",
    "Por ejemplo, se puede entrenar una SVM para clasificar imágenes de gatos y perros utilizando características extraídas de las imágenes, como texturas y formas. <br>\n",
    "Con este mismo enfoque podemos tambièn realizar reconocimienot facial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install numpy pandas matplotlib scikit-learn opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import Bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de imágenes de muestra\n",
    "# Podemos intentar con distintos datasets que vienen integrados en sklearn\n",
    "# siempre y cuando regrese una lista \n",
    "from sklearn.datasets import load_sample_images\n",
    "\n",
    "dataset = load_sample_images()\n",
    "images = dataset.images\n",
    "\n",
    "# Función para extraer características de una imagen\n",
    "# Aquí dividimos la imagen en una cuadrícula con la cual vamos a obtener los colores\n",
    "# para ir identificando regiones o características\n",
    "def extract_features(image, grid_size=(10, 10)):\n",
    "    height, width, _ = image.shape\n",
    "    features = []\n",
    "    for row in range(0, height, grid_size[0]):\n",
    "        for col in range(0, width, grid_size[1]):\n",
    "            region = image[row:row + grid_size[0], col:col + grid_size[1]]\n",
    "            avg_color = np.mean(region, axis=(0, 1))\n",
    "            features.append(avg_color)\n",
    "    return np.array(features)\n",
    "\n",
    "# Extraer características de las imágenes\n",
    "X = []\n",
    "y = []\n",
    "for idx, image in enumerate(images):\n",
    "    features = extract_features(image)\n",
    "    X.append(features)\n",
    "    y.append(np.full(features.shape[0], idx))  # Etiquetamos cada región de la imagen con el índice de la imagen\n",
    "\n",
    "# Convertir listas a arrays numpy\n",
    "X = np.vstack(X)\n",
    "y = np.concatenate(y)\n",
    "\n",
    "# print(X)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "# X variables que se usarán para la predicción\n",
    "# y variable que queremos predecir\n",
    "# test_size=0.2: indica que usaremos el 20% de los datos para el conjunto de prueba y el 80% para el conjunto de entrenamiento\n",
    "# Conjunto de entrenamiento se usa para entrenar el modelo, se usa para enseñar al modelo la relacion entre los patrones en los datos (mientras mas, mejor)\n",
    "# Conjunto de prueba se usa para comparar las predicciones y ver que tan acertadas son\n",
    "# random_state: se utiliza para controlar cómo se dividen los datos aleatorios. Si dos personas ejecutan la misma función con el mismo valor para random_state, \n",
    "#   obtendrán exactamente la misma división de datos (pruebas y entrenamiento).\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Entrenar el modelo SVM\n",
    "# linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’\n",
    "svm = SVC(kernel='rbf')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "\n",
    "# Matriz de confusion\n",
    "# TP (True Positives): Las predicciones correctas donde el modelo predice la clase positiva correcta.\n",
    "# FP (False Positives): Las predicciones incorrectas donde el modelo predice la clase positiva pero la instancia es negativa.\n",
    "# FN (False Negatives): Las predicciones incorrectas donde el modelo predice la clase negativa pero la instancia es positiva.\n",
    "# TN (True Negatives): Las predicciones correctas donde el modelo predice la clase negativa correcta.\n",
    "\n",
    "#                  Predicción Positiva\t   Predicción Negativa\n",
    "# Clase Positiva\t        TP\t                      FN\n",
    "# Clase Negativa\t        FP                        TN\n",
    "print(\"Mátriz de confusión\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Precisión (Precision): La proporción de verdaderos positivos sobre el total de predicciones positivas (TP / (TP + FP)).\n",
    "# Cobertura (Recall): La proporción de verdaderos positivos sobre el total de instancias verdaderamente positivas (TP / (TP + FN)).\n",
    "# F1 Score: La media armónica de precisión y cobertura, proporcionando un balance entre ambas métricas (2 * (Precision * Recall) / (Precision + Recall)).\n",
    "# Soporte (Support): El número de ocurrencias reales de la clase en los datos.\n",
    "print(\"Clasificación de reporte\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El siguiente código nos muestra la imagen seleccionada con la cuadrícula previamente trazada\n",
    "# y algunos patrones detectados por la SVM (basado en el color)\n",
    "# Esto nos puede ayudar para detectar objetos en imágenes\n",
    "import cv2\n",
    "def visualize_predictions(image, model, grid_size=(10, 10)):\n",
    "    features = extract_features(image, grid_size)\n",
    "    features = scaler.transform(features)\n",
    "    predictions = model.predict(features)\n",
    "    height, width, _ = image.shape\n",
    "    result = image.copy()\n",
    "    for idx, (row, col) in enumerate([(i, j) for i in range(0, height, grid_size[0]) for j in range(0, width, grid_size[1])]):\n",
    "        color = (0, 255, 0) if predictions[idx] == 0 else (0, 0, 255)\n",
    "        cv2.rectangle(result, (col, row), (col + grid_size[1], row + grid_size[0]), color, 1)\n",
    "    plt.imshow(result)\n",
    "    plt.title('Predicciones sobre la imagen')\n",
    "    plt.show()\n",
    "\n",
    "# Visualizar predicciones en la primera imagen\n",
    "visualize_predictions(images[1], svm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
