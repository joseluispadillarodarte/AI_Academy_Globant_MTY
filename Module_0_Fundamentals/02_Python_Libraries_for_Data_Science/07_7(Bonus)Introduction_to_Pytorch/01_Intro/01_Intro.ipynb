{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "PyTorch is a machine learning library based on the Torch library. It provides flexible tools for machine learning practitioners and researchers to build and train neural networks. It can be used for applications such as computer vision and natural language processing, originally developed by Meta AI and now part of the Linux Foundation umbrella. \n",
    "\n",
    "Below is a comprehensive summary of PyTorch fundamentals, which covers key aspects such as its core components, data handling, model building, and training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Fundamentals\n",
    "\n",
    "\n",
    "#### 1. Introduction to PyTorch\n",
    "- **Overview:** PyTorch is a dynamic, flexible framework for deep learning, known for its ease of use and efficient handling of tensors.\n",
    "- **Dynamic Computation Graphs:** Unlike static graph frameworks (like TensorFlow 1.x), PyTorch builds the computation graph dynamically, which makes it intuitive and easy to debug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Tensors\n",
    "- **Definition:** Tensors are the core data structure in PyTorch, analogous to NumPy arrays but with GPU acceleration.\n",
    "\n",
    "- **Creation and Initialization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Creating a tensor from a list\n",
    "x = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Creating a tensor of a specific shape filled with zeros\n",
    "zeros = torch.zeros((2, 3))\n",
    "\n",
    "# Creating a tensor with random values\n",
    "random_tensor = torch.randn((3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Operations:** PyTorch supports various tensor operations like slicing, reshaping, arithmetic operations, and matrix multiplications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + 2        # Element-wise addition\n",
    "z = torch.matmul(x, y)  # Matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Autograd (Automatic Differentation)\n",
    "\n",
    "- **Gradient Computation:** PyTorch’s **autograd** module automatically computes gradients, which are essential for backpropagation in neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "y = x * 2\n",
    "y.backward(torch.tensor([1.0, 1.0]))  # Computes the gradients\n",
    "print(x.grad)  # Output: tensor([2., 2.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Dynamic Graphs:** Each computation in PyTorch builds a computational graph dynamically, allowing for flexible model design and easy debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Building Neural Networks\n",
    "\n",
    "- **torch.nn Module:** Provides tools to construct neural networks, including predefined layers and loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Forward Method:** Defines the forward pass of the network. PyTorch’s autograd automatically handles the backward pass.\n",
    "\n",
    "#### 5. Optimazation\n",
    "\n",
    "- **Optimizers:** PyTorch provides a variety of optimization algorithms in the torch.optim module, such as SGD, Adam, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = SimpleNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Training Loop:** Typical training loop involves forward pass, loss computation, backward pass (gradient calculation), and weight updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()   # Zero the gradient buffers\n",
    "    output = model(input)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()        # Update the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Data Handling\n",
    "\n",
    "- **torch.utils.data Module:** Provides utilities to work with data, including **Dataset** and **DataLoader** for loading data in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "dataset = CustomDataset(data, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Transforms:** Data augmentation and preprocessing using **torchvision.transforms** (common in image processing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. GPU Acceleration\n",
    "\n",
    "- **CUDA Support:** PyTorch easily leverages NVIDIA GPUs for accelerated computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "input = input.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Saving and Loading Models\n",
    "\n",
    "- **Checkpointing:** PyTorch provides utilities to save and load models and optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Loading model\n",
    "model = SimpleNN()\n",
    "model.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Common Libraries and Extensions\n",
    "\n",
    "- **TorchVision:** For computer vision applications (datasets, models, transformations).\n",
    "- **TorchText:** For natural language processing tasks.\n",
    "- **TorchAudio:** For audio and speech processing.\n",
    "- **PyTorch Lightning:** Provides a high-level interface for PyTorch to reduce boilerplate code.\n",
    "\n",
    "### 10. Debugging and Visualization\n",
    "\n",
    "- **torchsummary:** Provides a summary of the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 128, 128))  # Example for an image model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **TensorBoard:** PyTorch supports integration with TensorBoard for visualizing training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "writer.add_scalar('Loss/train', loss, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Deployment and Inference\n",
    "\n",
    "- **TorchScript:** Allows exporting PyTorch models for efficient deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_model = torch.jit.script(model)\n",
    "torch.jit.save(scripted_model, 'scripted_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ONNX:** PyTorch models can be exported to ONNX format for interoperability with other frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, input, 'model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Community and Ecosystem\n",
    "\n",
    "- **Documentation:** Comprehensive and well-maintained official documentation.\n",
    "- **Tutorials and Examples:** Numerous tutorials available through the PyTorch website and community contributions.\n",
    "- **Community Support:** Active community on forums, GitHub, and social media channels.\n",
    "\n",
    "# Conclusion.\n",
    "\n",
    "PyTorch offers a robust and flexible platform for developing and experimenting with deep learning models. Its dynamic computation graph, ease of use, and extensive ecosystem make it a preferred choice for many practitioners in academia and industry. By mastering PyTorch’s core concepts—from tensor operations and automatic differentiation to model building and deployment—you can efficiently develop and deploy advanced deep learning models.\n",
    "\n",
    "# Additional Resources:\n",
    "\n",
    "- [Official Pytorch Documentation](https://pytorch.org/docs/stable/index.html)\n",
    "- [Learning Pytorch with Examples](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html)\n",
    "- [Deep Learning with Pytorch: A 60 minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
